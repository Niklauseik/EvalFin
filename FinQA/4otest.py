import openai
import pandas as pd
import os

# è¯»å– OpenAI API Key
from utils import config_manager
config_manager = config_manager.ConfigManager()
api_key = config_manager.get_api_key("openai")

# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
client = openai.OpenAI(api_key=api_key)

# **Fine-tuned Model (GPT-4o-mini)**
fine_tuned_model = "ft:gpt-4o-mini-2024-07-18:personal:answer-first:B44PSLIx"  # âœ… ä½ çš„å¾®è°ƒæ¨¡å‹ ID

# è¯»å–å®Œæ•´æµ‹è¯•æ•°æ®é›†
test_file = "datasets/finqa.csv"
df = pd.read_csv(test_file)

# **éšæœºæŠ½å– 100 æ¡æµ‹è¯•æ•°æ®**
df_sampled = df.sample(n=100, random_state=42).reset_index(drop=True)

# **æ›´æ–°ç»“æœå­˜å‚¨ç›®å½•**
results_dir = "results/finqa/answer_first_test"
os.makedirs(results_dir, exist_ok=True)

# **åˆå§‹åŒ–é¢„æµ‹åˆ—è¡¨**
predictions = []

# **éå†æŠ½æ ·æµ‹è¯•æ•°æ®è¿›è¡Œæ¨ç†**
for i, row in df_sampled.iterrows():
    prompt = row["query"]  # è¯»å–é—®é¢˜å’Œä¸Šä¸‹æ–‡
    true_answer = row["answer"]  # çœŸå®ç­”æ¡ˆ

    try:
        # **å‘é€ API è¯·æ±‚**
        response = client.chat.completions.create(
            model=fine_tuned_model,
            messages=[{"role": "user", "content": prompt}]
        )

        # **è·å–æ¨¡å‹è¿”å›çš„ç­”æ¡ˆ**
        predicted_answer = response.choices[0].message.content.strip()
        predictions.append(predicted_answer)

    except Exception as e:
        print(f"âŒ é¢„æµ‹å¤±è´¥ï¼Œé”™è¯¯: {e}")
        predictions.append("error")  # å¤±è´¥æ—¶å¡«å…… "error"

# **å°†é¢„æµ‹ç»“æœæ·»åŠ åˆ° DataFrame**
df_sampled["prediction"] = predictions

# **ä¿å­˜é¢„æµ‹ç»“æœ CSV**
results_file = os.path.join(results_dir, "qa_100_predictions.csv")
df_sampled.to_csv(results_file, index=False)
print(f"âœ… é¢„æµ‹ç»“æœå·²ä¿å­˜è‡³: {results_file}")

# **ä¸‹ä¸€æ­¥**
print("ğŸš€ è¯·æ‰‹åŠ¨æ£€æŸ¥éƒ¨åˆ†é¢„æµ‹ç»“æœï¼Œä»¥ç¡®ä¿æ ¼å¼æ­£ç¡®ï¼")
